\chapter{Теоретические основы анализа текстовых данных}

В данной главе описаны методы и концепции, применяющиеся в
задачах анализа текста, так как они используются в подходе
к решению поставленной задачи (см. главу~\ref{ch:problem_solving}).

В разделе~\ref{sec:term_document_matrix} приводится описание
концепции <<матрица “термин-документ”>>.

В разделе~\ref{sec:latent_semantic_analysis} описан подход,
именуемый <<латентным семантическим анализом>>.

В разделе~\ref{sec:latent_semantic_analysis} описан подход,
который называется <<векторное представление слов>>.

\section{Матрица <<термин-документ>>}
\label{sec:term_document_matrix}

Матрица <<термин-документ>> является одной из ключевых концепцией,
использующихся в дисциплине текстового информационного 
поиска~\cite{manning2008introduction}. 

\textit{Термином} называется некоторая атомарная лингвистическая
единица в языке. Обычно терминами являются слова, поэтому иногда
говорят \textit{слова}, подразумевая под этим понятием термины.

\textit{Документом} называется некоторая конечная последовательность
терминов. Документами в зависимости от области применения данной концепции
могут являться книги, статьи или веб-страницы.

\textit{Коллекцией} называется некоторое конечное множество документов.

Пусть имеется коллекция документов:
\[
    \mathcal{D} = \{\mathcal{D}_1, \mathcal{D}_2,...,\mathcal{D}_n\}.
\]
Введём множество всех терминов, присутствующих в коллекции:
\[
    T = \{t \colon t \in \bigcup_{j=1}^{n} \mathcal{D}_j\} = \{t_i\}_{i=1}^{m}.
\]
Подход заключается в том, чтобы описать данные матрицей 
$D \in \mathbb{R}^{m \times n}$, каждый элемент $d_{ij}$ которой будет
означать <<степень принадлежности>> термина $i$ документу $j$. То есть,
чем больше значение элемента $d_{ij}$, тем больше термин $i$ <<описывает>>
документ $j$.

Элементы данной матрицы могут вычисляться различными способами. Для описания
формул, по которым вычисляются эти элементы, введём вспомогательные величины:
\[
    \mathrm{tf}_{ij} = \sum_{t \in \mathcal{D}_j} [t_i = t],
\]
\[
    \mathrm{df}_{i} = \sum_{j=1}^{n} [t_i \in \mathcal{D}_j],
\]
\[
    \mathrm{gf}_{i} = \sum_{j=1}^{n} \mathrm{tf}_{ij},
\]
где выражение $[\cdot]$ равно единице, если внутри находится истинный
предикат, иначе выражение равно нулю. Таким образом $\mathrm{tf}_{ij}$~---
число встреч термина $i$ в документе $j$, $\mathrm{df}_{i}$~---
число документов в которых встречается термин $i$, а $\mathrm{gf}_{i}$~---
число втреч термина $i$ во всей коллекции.

Обычно для вычисления элементов матрицы <<термин-документ>> используется
\textit{формула TF-IDF}, которая имеет следующий вид:
\begin{equation}\label{eq:tf_idf}
    d_{ij} = \mathrm{tf}_{ij} \cdot \log{\frac{n}{\mathrm{df}_{i}}}.
\end{equation}
Формулу TF-IDF естественным образом можно обобщить:
\begin{equation}\label{eq:general_tfidf}
d_{ij} = \begin{cases}
    0,& \mathrm{tf}_{ij} = 0,\\
    l(\mathrm{tf}_{ij}) \cdot g(\frac{n}{\mathrm{df}_{i}}),& \mathrm{tf}_{ij} \ne 0,
         \end{cases}
\end{equation}
где $f$ и $g$~--- произвольные неотрицательные неубывающие функции определённые
на промежутке $\left[1, +\infty \right]$. В
таблице~\ref{tab:f_g_examples} приведены примеры функций $f$ и $g$,
которые могут быть использованы.

\begin{table}[!h]
    \caption{Примеры функций $f$ и $g$ в обобщённой формуле TF-IDF}\label{tab:f_g_examples}
\centering
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}\hline
    \boldmath$f(x)$ & $1$ & $\log{x}$ & $\log{x}$ & $\log{x}$ & $\sqrt{x}$ & $\sqrt{x}$ & $\sqrt{x}$ & $x$ & $x$ & $x$ \\\hline
    \boldmath$g(x)$ & $1$ & $1$ & $\log{x}$ & $\sqrt{x}$ & $1$ & $\log{x}$ & $\sqrt{x}$ & $1$ & $\log{x}$ & $\sqrt{x}$ \\\hline
\end{tabular}
\end{table}

Ещё одним распространённым способом вычисления коэффициентов
матрицы <<термин-документ>> является формула \textit{log-entropy}.
Она имеет следующий вид:
\begin{equation}\label{eq:log_entropy}
    d_{ij} = \log{(\mathrm{tf}_{ij} + 1)} \cdot
    (1 + \sum_{j=1}^{n} \frac{p_{ij} \cdot \log{p_{ij}}}{\log{n}}),
    p_{ij} = \frac{\mathrm{tf}_{ij}}{\mathrm{gf}_i}.
\end{equation}

Существуют также и другие способы вычисления элементов
матрицы <<термин-документ>>, но так как в рамках настоящего исследования
они не использовались, их рассмотрение будет опущено.

\section{Латентный семантический анализ}
\label{sec:latent_semantic_analysis}

\section{Векторное представление слов}
\label{sec:word_embedding}

\chapterconclusion

Выводы выводы
